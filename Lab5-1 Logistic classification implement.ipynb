{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5-1 \n",
    "### logistic Regression\n",
    "Regression 우리가 가설로 예측한 값(H) 와 실제 값(X) 사이의 차이의 평균(cost)를 최소화 하는 W를 찾는 것이 목적 \n",
    "만약 실제 값과 예측한 가설값이 큰  차이가 있으면 우리가 설계한 model에게 엄격히 제한 할 수 있어야 한다. \n",
    "즉 cost 값이 -> 0 이 되는 optimaize 한 solution ==> Goal\n",
    "구하는 방법 : 해당 지점에서 미분을 통한 Gradient Descending 을 이용하여 기울기 방향의 반대 방향으로 향하게 되면 cost가 0 인 점에 도달할 수 있다. 그때 이동하는 양은 a(learnig rate)이라고 한다.\n",
    "<br>\n",
    "Binary Calssification 에서는 항상 우리가 원하는 값 y 는  0 , 1 로 encoding 되어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2], [2, 3],[3, 1], [4, 3], [5, 3], [6, 2]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]\n",
    "#placeholder 다량의 데이터를 출력하기 위해placeholder를 설정하는 것이 용이하다.\n",
    "#shape 해석은 X 같은 경우 위 x_data 와 같이 \"어떤 데이터 값이든 float32 데이터 타입의 데이터가 2개씩 들어와야한다.\" 라고 해석 할 수 있다.\n",
    "X = tf.placeholder(tf.float32, shape=[Node,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[Node,1])          \n",
    "# weight는 input 값으로 2개 output 출력값으로 1개가 나오도록 설정 해놓았다.\n",
    "# 마찬가지로 bias 값도 y 값과 같이 output의 값이 1개로 선언\n",
    "W = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
    "B = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid를 활용한 Hypothesis : tensorflow에서 sigmoid 함수를 제공해준다.\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "#hypothesis 를 이용해 node 생성 시 cost 정의\n",
    "#이론시간에 배운 logistic classification를 구현 if condition을 사용하지 않고 y의 0 ,1 encoding 성질을 이용해 하나의 식으로 표현 가능하다.\n",
    "#기존의 sigmoid 를 사용 할 시에는 각 지점마다 local minimum이 존재 하기 때문에 이것을 해결하기 위해 역함수 log 를 사용하여 loss function을 작성한다.\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1- Y) * tf.log(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"300\" alt=\"2018-11-14 11 18 17\" src=\"https://user-images.githubusercontent.com/33486820/48455580-21876c00-e7ff-11e8-8216-032a8433f11d.png\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실제 학습 그래프 즉,training이 일어나는 부분 GradientDescent를 이용하여 최소의 cost를 찾는다. 여기서 learning rate 상수값은 0.01로 설정 해준다.\n",
    "train = tf.train.GradientDescentOptimaizer(learnin_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#가설한 값이 0.5보다 큰지 작은지 tf.float32로 캐스팅 하면 True : 1 False: 0 으로 나온다\n",
    "#그렇게 얻어진 값을 실제 Y값과 비교한다.\n",
    "rpedicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(Tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "학습의 과정\n",
    "1. tf.Session() 을 구축\n",
    "2. variable 초기화 시킨후 loop 를 돌면서 학습을 진행한다. \n",
    "3. 학습 된 모델을 가지고 hypothesis 와 predicted  값을 실제 Y값을 비교 후 Accuracy 를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#당뇨병 예측\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  \n",
    "\n",
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "#x_data 총 8개 \n",
    "X = tf.placeholder(tf.float32, shape=[None, 8]) \n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\( \\begin{split}\n",
    "\\bigtriangledown_{\\theta} \\pi_{\\theta}(s,a) &= \\pi_{\\theta}(s,a) \\frac{\\bigtriangledown_{\\theta} \\pi_{\\theta}(s,a)}{\\pi_{\\theta}(s,a)} \\\\\n",
    "&= \\pi_{\\theta}(s,a) \\bigtriangledown_{\\theta} \\log \\pi_{\\theta}(s,a) \\end{split} \\\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\(\\begin{split} J(\\theta)\n",
    "&= \\mathbb{E}_{\\pi_{\\theta}}[r] \\\\\n",
    "&= \\sum_{s \\in \\mathcal{S}}d(s) \\sum_{a \\in \\mathcal{A}} \\pi_\\theta(s,a)R_{s,a}\n",
    "\\end{split}\\\\)\n",
    "<br><br>\n",
    "\\\\(\\begin{split} \\bigtriangledown_{\\theta} J(\\theta)\n",
    "&= \\sum_{s \\in \\mathcal{S}}d(s) \\sum_{a \\in \\mathcal{A}} \\pi_\\theta(s,a) \\bigtriangledown_{\\theta} \\log \\pi_{\\theta}(s,a)R_{s,a} \\\\\n",
    "&= \\mathbb{E}_{\\pi_\\theta}[\\bigtriangledown_{\\theta} \\log \\pi_{\\theta}(s,a)r]\n",
    "\\end{split}\\\\)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
